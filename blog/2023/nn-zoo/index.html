<!DOCTYPE html>
<html lang="en">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      Crafting Neural Networks | Algotechniq 
    
  
</title>
<meta name="author" content="Algotechniq ">
<meta name="description" content="Building layers bottom-up">

  <meta name="keywords" content="on-road anomaly detection, structural damage detection, motorist safety, computer vision, machine learning, deep learning, transfer learning, artificial intelligence, Nvidia, Orin, Automatic Claim Estimator, Insurance, Vehicle Damage Assessment, Computer Vision, Deep Learning, Instance Segmentation, Mask R-CNN, Object Detection, Vehicle Damaged Detection, pavement distresses, road condition monitoring, deep learning in road damage detection, built-in vehicle cameras, GPS sensors in road condition monitoring, pavement damage detection using deep learning, machine learning in road damage detection, Algorithms, Design, Experimentation, Measurement, computer vision (CV), edge computing, Internet of things (IoT), graphical processing unit (GPU), single-board computers (SBCs), smart cities">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->


<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">


  <!-- Sidebar Table of Contents -->
  <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet">


<!-- Styles -->

<!-- pseudocode -->



  <link rel="shortcut icon" href="/assets/img/faviconalgo.webp?e023f3f8fee08ff888d2356ef91d4268">

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="https://www.algotechniq.com/blog/2023/nn-zoo/">

<!-- Dark Mode -->
<script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script>


<!-- GeoJSON support via Leaflet -->


<!-- diff2html -->






  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/">
          
            
              <span class="font-weight-bold">Algotechniq</span>
            
            
            
          
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">home
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/projects/">projects
                    
                  </a>
                </li>
              
            
          
            
          
            
              
                
                <li class="nav-item active">
                  
                  <a class="nav-link" href="/blog/">blog
                    
                  </a>
                </li>
              
            
          
            
          
            
          
            
              
                
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/cv/">about
                    
                  </a>
                </li>
              
            
          
            
          
            
          
            
          
          
            <!-- Search -->
            <li class="nav-item">
              <button id="search-toggle" title="Search" onclick="openSearchModal()">
                <span class="nav-link">ctrl k <i class="ti ti-search"></i></span>
              </button>
            </li>
          
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        
          <div class="row">
            <!-- sidebar, which will move to the top on a small screen -->
            <div class="col-sm-3">
              <nav id="toc-sidebar" class="sticky-top"></nav>
            </div>
            <!-- main content area -->
            <div class="col-sm-9">







<div class="post">
  <header class="post-header">
    <h1 class="post-title">Crafting Neural Networks</h1>
    <p class="post-meta">
      Created in May 12, 2023
      
      
      
    </p>
    <p class="post-tags">
      
        <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>
      
      
          ·  
        
          
            <a href="/blog/tag/technote"> <i class="fa-solid fa-hashtag fa-sm"></i> technote</a>
          
          
        
      

      
          ·  
        
          
            <a href="/blog/category/algoblog">
              <i class="fa-solid fa-tag fa-sm"></i> Algoblog</a>
          
          
        
      
    </p>
  </header>

  <article class="post-content">
    
    <div id="markdown-content">
      <p>You might have visited the <a href="https://www.asimovinstitute.org/neural-network-zoo/" rel="external nofollow noopener" target="_blank">Neural Network Zoo</a>   <a class="citation" href="#proceedings2020047009">(Leijnen &amp; Veen, 2020)</a> or looked at <a href="https://resources.wolframcloud.com/NeuralNetRepository/" rel="external nofollow noopener" target="_blank">Wolfram Neural Net Repository</a> and wondered how these structures came about?</p>

<p>Well, these layers don’t just emerge randomly. They’re crafted with precision to cater to specific requirements of various tasks, always to enhance model performance.</p>

<h2 id="convolutional-layers">Convolutional Layers</h2>

<p>For example, convolutional layers were developed to address the challenges of image processing. Digital pictures have high dimensionality and strong local relationships between pixels, which can be tricky to handle. Convolutional Layers are tailored to these characteristics, making them highly effective for analyzing images.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
    <img src="/assets/img/conv2d.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
    <img src="/assets/img/fcnn.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

    </div>
</div>
<div class="caption">
(Left) Illustrating the convolutional layer (Right) Layers connect to form a deep convolutional neural network. Click to Zoom.
</div>

<p>The formula for a 2D convolutional layer \(\mathbf{Y} = \mathbf{X}  \circledast \mathbf{K}\) is:</p>

\[y[i, j] = \sum_{m=0}^{M-1} \sum_{n=0}^{N-1} x[i+m, j+n] \cdot k[m, n]\]

<p>Where:</p>
<ul>
  <li>\(    y[i, j] \) is the output feature map.</li>
  <li>\(    x[i+m, j+n] \) is the input feature map.</li>
  <li>\(    k[m, n] \) is the convolutional kernel (filter).</li>
  <li>\(    b \) is the bias term.</li>
  <li>\(    M \) and \(    N \) are the dimensions of the kernel.</li>
</ul>

<p>Note that this formula assumes no bias, no padding and a stride of 1.</p>

<p>New layers are usually created to overcome current limitations or to better handle specific types of data or tasks. This leads AI researchers to constantly innovate, experimenting with different layer structures, activation functions, and training methods.</p>

<h2 id="hierarchical-feature-learning-hfl">Hierarchical Feature Learning (HFL)</h2>

<p>Another key concept in neural networks is “hierarchical feature learning,” <a class="citation" href="#Krizhevsky10.1145/3065386">(Krizhevsky et al., 2017)</a> where simple features detected by early layers (like edges in an image) are combined in later layers to form more complex patterns (like shapes or objects). This hierarchy allows the model to recognize intricate patterns in the data.</p>

<p>HFL can be formally described using the following algebraic formulation:</p>

<p>Let:</p>

<ul>
  <li>\(   \mathbf{X} \in \mathbb{R}^{d_0}\) represent the input data, where \(   d_0\) is the dimensionality of the input.</li>
  <li>\(   L\) be the total number of layers in the network.</li>
  <li>\(   \mathbf{H}^{(l)} \in \mathbb{R}^{d_l}\) represent the output (feature map) at layer \(   l\), where \(   d_l\) is the dimensionality of the feature space at layer \(   l\).</li>
  <li>\(   \mathbf{W}^{(l)} \in \mathbb{R}^{d_l \times d_{l-1}}\) represent the weight matrix for layer \(   l\).</li>
  <li>\(   \mathbf{b}^{(l)} \in \mathbb{R}^{d_l}\) represent the bias vector for layer \(   l\).</li>
  <li>\(   \sigma(\cdot)\) represent the activation function (e.g., ReLU, sigmoid, tanh).</li>
</ul>

<p>The hierarchical feature encoding can be described as:</p>

\[\mathbf{H}^{(l)} = \sigma\left(\mathbf{W}^{(l)} \mathbf{H}^{(l-1)} + \mathbf{b}^{(l)}\right), \quad \text{for } l = 1, 2, \ldots, L\]

<p>Where:</p>

<ul>
  <li>\(   \mathbf{H}^{(0)} = \mathbf{X}\), the initial input to the network.</li>
  <li>\(   \mathbf{H}^{(l)}\) represents the feature encoding at layer \(   l\), which serves as the input to the next layer.</li>
</ul>

<p>Low-Level Features (\(   \mathbf{H}^{(1)}\)) are the basic, primitive patterns detected by the initial layers of a neural network. These features are simple and localized, including edges that mark boundaries between different regions, corners where two edges meet, repetitive textures like those found in fabric or bricks, and simple geometric shapes such as circles, triangles, or rectangles.</p>

<p>Mid-Level Features (\(   \mathbf{H}^{(2)}, \mathbf{H}^{(3)}, \ldots\)) capture more complex patterns such as corners, contours, or parts of objects, using the low-level features as building blocks.</p>

<p>High-Level Features (\(   \mathbf{H}^{(L)}\)) are abstract, complex patterns identified by the deeper layers of a neural network. These features often combine multiple low-level elements. Examples include recognizing specific object parts like eyes, legs, or wings, and complete objects such as a face, car, or dog. Additionally, high-level features encompass semantic concepts like identifying a “crowd of people” or “traffic scene,” as well as broader scene understanding, such as recognizing an “urban landscape” or “natural environment.”</p>

<blockquote>
  <p>However, designing and training deep neural networks is challenging.</p>
</blockquote>

<p>Adding too many layers can lead to problems like overfitting, where the model performs well on training data but poorly on new data. Other issues, like the vanishing gradient problem, can also arise. To address these challenges, techniques like dropout layers, batch normalization, and architectures like ResNet (which uses skip connections) have been developed.</p>

<p>In summary, neural network layers are the result of careful research and innovation, constantly pushing the boundaries of AI. The real magic happens in how these layers learn and adapt to different tasks.</p>

    </div>
  </article>

  

  
    <h2>References</h2>
    <div class="publications">
      <h2 class="bibliography">2020</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="proceedings2020047009" class="col-sm-8">
    <!-- Title -->
    <div class="title">The Neural Network Zoo</div>
    <!-- Author -->
    <div class="author">
      

      
      Stefan
            Leijnen, and Fjodor van
            Veen
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Proceedings</em>,  2020
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://www.mdpi.com/2504-3900/47/1/9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://www.researchgate.net/publication/341373030_The_Neural_Network_Zoo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>An overview of neural network architectures is presented. Some of these architectures have been created in recent years, whereas others originate from many decades ago. Apart from providing a practical tool for comparing deep learning models, the Neural Network Zoo also uncovers a taxonomy of network architectures, their chronology, and traces back lineages and inspirations for these neural information processing systems.</p>
      </div>
    

    

    
  </div>
</div>
</li></ol>
<h2 class="bibliography">2017</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Krizhevsky10.1145/3065386" class="col-sm-8">
    <!-- Title -->
    <div class="title">ImageNet classification with deep convolutional neural networks</div>
    <!-- Author -->
    <div class="author">
      

      
      Alex
            Krizhevsky, Ilya
            Sutskever, and Geoffrey E.
            Hinton
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Commun. ACM</em>,  May 2017
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://dl.acm.org/doi/10.1145/3065386" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://dl.acm.org/doi/pdf/10.1145/3065386" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.</p>
      </div>
    

    

    
  </div>
</div>
</li></ol>
    </div>
  

  
    
      

  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/ai-on-jetson/">AI on Jetson</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/yolov8/">YOLO</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/pbdl-jupyter/">Deeply Learning Physics</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/jetson-evolution/">The Jetson Evolution</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/rooflinemodel/">Bounded Performance: Uncovering the Roofline Model</a>
  </li>



    
  

  
  
</div>
</div>
          </div>
        
      
    </div>

    <!-- Footer -->
    
  <footer class="fixed-bottom" role="contentinfo">
    <div class="container mt-0">
      © Copyright 2024
      Algotechniq
      
      . 
      
      
    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<!-- <script src="/assets/js/mdb.min.js"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
  <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>


    

    

    

    

    

    

    

    

    

  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>


  <!-- Sidebar Table of Contents -->
  <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script>


<!-- Bootstrap Table -->


<!-- Load Common JS -->
<script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script>
<script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script>
<script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script>

<!-- Jupyter Open External Links New Tab -->
<script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script>



    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>


  <script async src="https://badge.dimensions.ai/badge.js"></script>


    
  
    <!-- MathJax -->
    <script type="text/javascript">
      window.MathJax = {
        tex: {
          tags: 'ams',
        },
      };
    </script>
    <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script>
    <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script>
  


    

    



    
  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    /*
     * This JavaScript code has been adapted from the article
     * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar,
     * published on the website https://css-tricks.com on the 7th of May, 2014.
     * Couple of changes were made to the original code to make it compatible
     * with the `al-foio` theme.
     */
    const progressBar = $('#progress');
    /*
     * We set up the bar after all elements are done loading.
     * In some cases, if the images in the page are larger than the intended
     * size they'll have on the page, they'll be resized via CSS to accomodate
     * the desired size. This mistake, however, breaks the computations as the
     * scroll size is computed as soon as the elements finish loading.
     * To account for this, a minimal delay was introduced before computing the
     * values.
     */
    window.onload = function () {
      setTimeout(progressBarSetup, 50);
    };
    /*
     * We set up the bar according to the browser.
     * If the browser supports the progress element we use that.
     * Otherwise, we resize the bar thru CSS styling
     */
    function progressBarSetup() {
      if ('max' in document.createElement('progress')) {
        initializeProgressElement();
        $(document).on('scroll', function () {
          progressBar.attr({ value: getCurrentScrollPosition() });
        });
        $(window).on('resize', initializeProgressElement);
      } else {
        resizeProgressBar();
        $(document).on('scroll', resizeProgressBar);
        $(window).on('resize', resizeProgressBar);
      }
    }
    /*
     * The vertical scroll position is the same as the number of pixels that
     * are hidden from view above the scrollable area. Thus, a value > 0 is
     * how much the user has scrolled from the top
     */
    function getCurrentScrollPosition() {
      return $(window).scrollTop();
    }

    function initializeProgressElement() {
      let navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      progressBar.css({ top: navbarHeight });
      progressBar.attr({
        max: getDistanceToScroll(),
        value: getCurrentScrollPosition(),
      });
    }
    /*
     * The offset between the html document height and the browser viewport
     * height will be greater than zero if vertical scroll is possible.
     * This is the distance the user can scroll
     */
    function getDistanceToScroll() {
      return $(document).height() - $(window).height();
    }

    function resizeProgressBar() {
      progressBar.css({ width: getWidthPercentage() + '%' });
    }
    // The scroll ratio equals the percentage to resize the bar
    function getWidthPercentage() {
      return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
    }
  </script>


    

    

    

    
  <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script>
  <script>
    addBackToTop();
  </script>


    
  <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script>
  <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys>
  <script>
    let searchTheme = determineComputedTheme();
    const ninjaKeys = document.querySelector('ninja-keys');

    if (searchTheme === 'dark') {
      ninjaKeys.classList.add('dark');
    } else {
      ninjaKeys.classList.remove('dark');
    }

    const openSearchModal = () => {
      // collapse navbarNav if expanded on mobile
      const $navbarNav = $('#navbarNav');
      if ($navbarNav.hasClass('show')) {
        $navbarNav.collapse('hide');
      }
      ninjaKeys.open();
    };
  </script>
  <script>
    // get the ninja-keys element
    const ninja = document.querySelector('ninja-keys');

    // add the home and posts menu items
    ninja.data = [{
        id: "nav-home",
        title: "home",
        section: "Navigation",
        handler: () => {
          window.location.href = "/";
        },
      },{id: "nav-projects",
              title: "projects",
              description: "A growing collection of Algotechniq projects",
              section: "Navigation",
              handler: () => {
                window.location.href = "/projects/";
              },
            },{id: "nav-blog",
              title: "blog",
              description: "",
              section: "Navigation",
              handler: () => {
                window.location.href = "/blog/";
              },
            },{id: "nav-about",
              title: "about",
              description: "Summary description of Algotechniq LLC.",
              section: "Navigation",
              handler: () => {
                window.location.href = "/cv/";
              },
            },{id: "post-ai-on-jetson",
          
            title: "AI on Jetson",
          
          description: "In four bipedal steps",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2024/ai-on-jetson/";
            
          },
        },{id: "post-yolo",
          
            title: "YOLO",
          
          description: "Illustrating a fast and accurate object detection algorithm",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2024/yolov8/";
            
          },
        },{id: "post-deeply-learning-physics",
          
            title: "Deeply Learning Physics",
          
          description: "A few notes in a Jupyter notebook",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2024/pbdl-jupyter/";
            
          },
        },{id: "post-the-jetson-evolution",
          
            title: "The Jetson Evolution",
          
          description: "As Nvidia evolves Jetson, embedded systems thrive",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2024/jetson-evolution/";
            
          },
        },{id: "post-bounded-performance-uncovering-the-roofline-model",
          
            title: "Bounded Performance: Uncovering the Roofline Model",
          
          description: "Is your AI algorithm computation-bound or memory-bound?",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/assets/pdf/roof.pdf";
            
          },
        },{id: "post-neural-nonlinearities",
          
            title: "Neural Nonlinearities",
          
          description: "What makes neural nets so powerful?",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/assets/pdf/nonlinear.pdf";
            
          },
        },{id: "post-ai-39-s-carbon-footprint",
          
            title: "AI's Carbon Footprint",
          
          description: "The quintillions are alarming",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2023/ai-carbon-footprint/";
            
          },
        },{id: "post-the-bottom-up-magic-of-deep-learning",
          
            title: "The Bottom-Up Magic of Deep Learning",
          
          description: "From alchemy to architecture",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2023/dnn-bottomup/";
            
          },
        },{id: "post-crafting-neural-networks",
          
            title: "Crafting Neural Networks",
          
          description: "Building layers bottom-up",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2023/nn-zoo/";
            
          },
        },{id: "post-claws-of-concern",
          
            title: "Claws of Concern",
          
          description: "Bears attacking Japan",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2023/bears-attack/";
            
          },
        },{id: "news-a-simple-inline-announcement",
              title: 'A simple inline announcement.',
              description: "",
              section: "News",},{id: "news-a-long-announcement-with-details",
              title: 'A long announcement with details',
              description: "",
              section: "News",handler: () => {
                  window.location.href = "/news/announcement_2/";
                },},{id: "news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",
              title: 'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',
              description: "",
              section: "News",},{id: "projects-highsafe",
              title: 'HighSafe',
              description: "Instant accident alerts for safer roads",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/1_project/";
                },},{id: "projects-deephole",
              title: 'DeepHole',
              description: "Real-time road quality detection on Edge",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/2_project/";
                },},{id: "projects-concretevision",
              title: 'ConcreteVision',
              description: "Real-time concrete pouring monitor",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/3_project/";
                },},{id: "projects-smartscan",
              title: 'SmartScan',
              description: "Detecting surface defects with deep learning",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/4_project/";
                },},{id: "projects-autoclaim-ai",
              title: 'AutoClaim AI',
              description: "Precision damage detection for smarter insurance",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/5_project/";
                },},{id: "projects-wildsight",
              title: 'WildSight',
              description: "Precision wildlife detection with deep learning",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/6_project/";
                },},{
            id: 'socials-email',
            title: 'Send email',
            section: 'Socials',
            handler: () => {
              window.open("mailto:%6B%61%6D%62%69%7A@%67%6D%61%69%6C.%63%6F%6D", "_blank");
            },
          },{
            id: 'socials-google-scholar',
            title: 'Google Scholar',
            section: 'Socials',
            handler: () => {
              window.open("https://scholar.google.com/citations?user=dV8LzD8AAAAJ", "_blank");
            },
          },];
  </script>
  <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script>


  </body>
</html>

<!DOCTYPE html>
<html lang="en">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      publications | Algotechniq 
    
  
</title>
<meta name="author" content="Algotechniq ">
<meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar.">

  <meta name="keywords" content="on-road anomaly detection, structural damage detection, motorist safety, computer vision, machine learning, deep learning, transfer learning, artificial intelligence, Nvidia, Orin, Automatic Claim Estimator, Insurance, Vehicle Damage Assessment, Computer Vision, Deep Learning, Instance Segmentation, Mask R-CNN, Object Detection, Vehicle Damaged Detection, pavement distresses, road condition monitoring, deep learning in road damage detection, built-in vehicle cameras, GPS sensors in road condition monitoring, pavement damage detection using deep learning, machine learning in road damage detection, Algorithms, Design, Experimentation, Measurement, computer vision (CV), edge computing, Internet of things (IoT), graphical processing unit (GPU), single-board computers (SBCs), smart cities">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->


<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">



<!-- Styles -->

<!-- pseudocode -->



  <link rel="shortcut icon" href="/assets/img/faviconalgo.webp?e023f3f8fee08ff888d2356ef91d4268">

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="https://www.algotechniq.com/publications/">

<!-- Dark Mode -->
<script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script>


<!-- GeoJSON support via Leaflet -->


<!-- diff2html -->






  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/">
          
            
              <span class="font-weight-bold">Algotechniq</span>
            
            
            
          
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">home
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/projects/">projects
                    
                  </a>
                </li>
              
            
          
            
          
            
              
                
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/blog/">blog
                    
                  </a>
                </li>
              
            
          
            
          
            
          
            
              
                
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/cv/">about
                    
                  </a>
                </li>
              
            
          
            
          
            
          
            
          
          
            <!-- Search -->
            <li class="nav-item">
              <button id="search-toggle" title="Search" onclick="openSearchModal()">
                <span class="nav-link">ctrl k <i class="ti ti-search"></i></span>
              </button>
            </li>
          
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        <div class="post">
  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p>
  </header>

  <article>
    <!-- _pages/publications.md -->

<!-- Bibsearch Feature -->

<script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script>

<p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p>

<div class="publications">

<h2 class="bibliography">2024</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">Springer</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="10.1007/978-3-031-62281-6_30" class="col-sm-8">
    <!-- Title -->
    <div class="title">Wild Animal Recognition Using an Edge Device</div>
    <!-- Author -->
    <div class="author">
      

      
      Vincenzo
            Russo, Paola
            Barra, Augusto
            Tortora, and
        <span class="more-authors" title="click to view 4 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '4 more authors' ? 'Guido Russo, Pietro Battistoni, Monica Sebillo, Genoveffa Tortora' : '4 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">4 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Intelligent Computing</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://link.springer.com/chapter/10.1007/978-3-031-62281-6_30" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Neural networks and deep learning are in rapid development; new technologies and increasingly high-performance computing centres allow operations to be carried out that, until a few years ago, were impossible due to excessive processing times. The possibility of exploiting an Edge/Cloud configuration allows speed in training neural networks, ability to operate in real-time, elasticity, and resistance of the entire system in the event of a failure. This configuration helps reduce costs by using less expensive tools in the sensing and edge regions. In this work, an edge computing system was implemented to recognise wild animals such as goats and wild boars. The image recognition problem was therefore addressed by exploiting transfer learning techniques on two state-of-the-art methods: YOLOv5 and EfficientNet. The comparison of the results highlighted the pros and cons of the two methods.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Gholami10477550" class="col-sm-8">
    <!-- Title -->
    <div class="title">AI and Memory Wall</div>
    <!-- Author -->
    <div class="author">
      

      
      Amir
            Gholami, Zhewei
            Yao, Sehoon
            Kim, and
        <span class="more-authors" title="click to view 3 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '3 more authors' ? 'Coleman Hooper, Michael W. Mahoney, Kurt Keutzer' : '3 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">3 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>IEEE Micro</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://ieeexplore.ieee.org/abstract/document/10477550" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://arxiv.org/pdf/2403.14123" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>The availability of unprecedented unsupervised training data, along with neural scaling laws, has resulted in an unprecedented surge in model size and compute requirements for serving/training large language models. However, the main performance bottleneck is increasingly shifting to memory bandwidth. Over the past 20 years, peak server hardware floating-point operations per second have been scaling at 3.0 times per two years, outpacing the growth of dynamic random-access memory and interconnect bandwidth, which have only scaled at 1.6 and 1.4 times every two years, respectively. This disparity has made memory, rather than compute, the primary bottleneck in AI applications, particularly in serving. Here, we analyze encoder and decoder transformer models and show how memory bandwidth can become the dominant bottleneck for decoder models. We argue for a redesign in model architecture, training, and deployment strategies to overcome this memory limitation.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2023</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="vehicles5030051" class="col-sm-8">
    <!-- Title -->
    <div class="title">Road Condition Monitoring Using Vehicle Built-in Cameras and GPS Sensors: A Deep Learning Approach</div>
    <!-- Author -->
    <div class="author">
      

      
      Cuthbert
            Ruseruka, Judith
            Mwakalonge, Gurcan
            Comert, and
        <span class="more-authors" title="click to view 2 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '2 more authors' ? 'Saidi Siuhi, Judy Perkins' : '2 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">2 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Vehicles</em>,  2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Road authorities worldwide can leverage the advances in vehicle technology by continuously monitoring their roads’ conditions to minimize road maintenance costs. The existing methods for carrying out road condition surveys involve manual observations using standard survey forms, performed by qualified personnel. These methods are expensive, time-consuming, infrequent, and can hardly provide real-time information. Some automated approaches also exist but are very expensive since they require special vehicles equipped with computing devices and sensors for data collection and processing. This research aims to leverage the advances in vehicle technology in providing a cheap and real-time approach to carry out road condition monitoring (RCM). This study developed a deep learning model using the You Only Look Once, Version 5 (YOLOv5) algorithm that was trained to capture and categorize flexible pavement distresses (FPD) and reached 95% precision, 93.4% recall, and 97.2% mean Average Precision. Using vehicle built-in cameras and GPS sensors, these distresses were detected, images were captured, and locations were recorded. This was validated on campus roads and parking lots using a car featured with a built-in camera and GPS. The vehicles’ built-in technologies provided a more cost-effective and efficient road condition monitoring approach that could also provide real-time road conditions.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Mallios10194904" class="col-sm-8">
    <!-- Title -->
    <div class="title">Vehicle Damage Severity Estimation for Insurance Operations Using In-The-Wild Mobile Images</div>
    <!-- Author -->
    <div class="author">
      

      
      Dimitrios
            Mallios, Li
            Xiaofei, Niall
            McLaughlin, and
        <span class="more-authors" title="click to view 3 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '3 more authors' ? 'Jesus Martinez Del Rincon, Clare Galbraith, Rory Garland' : '3 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">3 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>IEEE Access</em>,  2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
      
        
          <a href="https://ieeexplore.ieee.org/abstract/document/10194904" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10194904" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="jimaging9100193" class="col-sm-8">
    <!-- Title -->
    <div class="title">A Systematic Review on Deep Learning with CNNs Applied to Surface Defect Detection</div>
    <!-- Author -->
    <div class="author">
      

      
      Esteban
            Cumbajin, Nuno
            Rodrigues, Paulo
            Costa, and
        <span class="more-authors" title="click to view 7 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '7 more authors' ? 'Rolando Miragaia, Luís Frazão, Nuno Costa, Antonio Fernández-Caballero, Jorge Carneiro, Leire H. Buruberri, António Pereira' : '7 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">7 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Journal of Imaging</em>,  2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://www.mdpi.com/2313-433X/9/10/193" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Surface defect detection with machine learning has become an important tool in industries and a large field of study for researchers or workers in recent years. It is necessary to have a simplified source of information that helps us to better focus on one type of surface. In this systematic review, we present a classification for surface defect detection based on convolutional neural networks (CNNs) focused on surface types. Findings: Out of 253 records identified, 59 primary studies were eligible. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, we analyzed the structures of each study and the concepts related to defects and their types on surfaces. The presented review is mainly focused on finding a classification for the types of surfaces most used in industry (metal, building, ceramic, wood, and special). We delve into the specifics of each surface category, offering illustrative examples of their applications within both industrial and laboratory settings. Furthermore, we propose a new taxonomy of machine learning based on the obtained results and collected information. We summarized the studies and extracted the main characteristics such as type of surface, problem types, timeline, type of network, techniques, and datasets. Among the most relevant results of our analysis, we found that the metallic surface is the most used, as it is the one found in 62.71% of the studies, and the most prevalent problem type is classification, accounting for 49.15% of the total. Furthermore, we observe that transfer learning was employed in 83.05% of the studies, while data augmentation was utilized in 59.32%. Our findings also provide insights into the cameras most frequently employed, along with the strategies adopted to address illumination challenges present in certain articles and the approach to creating datasets for real-world applications. The main results presented in this review allow for a quick and efficient search of information for researchers and professionals interested in improving the results of their defect detection projects. Finally, we analyzed the trends that could open new fields of study for future research in the area of surface defect detection.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2022</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="su142214859" class="col-sm-8">
    <!-- Title -->
    <div class="title">A Systematic Review of Traffic Incident Detection Algorithms</div>
    <!-- Author -->
    <div class="author">
      

      
      Osama
            ElSahly, and Akmal
            Abdelfatah
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Sustainability</em>,  2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://www.mdpi.com/2071-1050/14/22/14859" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Traffic incidents have negative impacts on traffic flow and the gross domestic product of most countries. In addition, they may result in fatalities and injuries. Thus, efficient incident detection systems have a vital role in restoring normal traffic conditions on the roads and saving lives and properties. Researchers have realized the importance of Automatic Incident Detection (AID) systems and conducted several studies to develop AID systems to quickly detect traffic incidents with an acceptable performance level. An incident detection system mainly consists of two modules: a data collection module and a data processing module. The performance of AID systems is assessed using three performance measures; Detection Rate (DR), False Alarm Rate (FAR) and Mean Time to Detect (MTTD). Based on data processing and incident detection algorithms, AID can be categorized into four categories: comparative, statistical, artificial intelligence-based and video–image processing algorithms. The aim of this paper is to investigate and summarize the existing AID systems by assessing their performance, strengths, limitations and their corresponding data collection and data processing techniques. This is useful in highlighting the shortcomings of these systems and providing potential solutions that future research should focus on. The literature is sought through an extensive review of the existing refereed publications using the Google Scholar search engine and Scopus database. The methodology adopted for this research is a systematic literature review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. This study can serve as a reference for researchers who are interested in developing new AID systems.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="VANRUITENBEEK2022100332" class="col-sm-8">
    <!-- Title -->
    <div class="title">Convolutional Neural Networks for vehicle damage detection</div>
    <!-- Author -->
    <div class="author">
      

      
      R.E.
            van Ruitenbeek, and S.
            Bhulai
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Machine Learning with Applications</em>,  2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://www.sciencedirect.com/science/article/pii/S2666827022000433" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Vehicle damages are increasingly becoming a liability for shared mobility services. The large number of handovers between drivers demands for an accurate and fast inspection system, which locates small damages and classifies these into the correct damage category. To address this, a damage detection model is developed to locate vehicle damages and classify these into twelve categories. Multiple deep learning algorithms are used, and the effect of different transfer learning and training strategies is evaluated, to optimize the detection performance. The final model, trained on more than 10,000 damage images, is able to accurately detect small damages under various conditions such as water and dirt. A performance evaluation with domain experts shows, that the model achieves comparable performance. In addition, the model is evaluated in a specially designed light street, indicating that strong reflections complicate the detection performance.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2021</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Arnab9710415" class="col-sm-8">
    <!-- Title -->
    <div class="title">ViViT: A Video Vision Transformer</div>
    <!-- Author -->
    <div class="author">
      

      
      A.
            Arnab, M.
            Dehghani, G.
            Heigold, and
        <span class="more-authors" title="click to view 3 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '3 more authors' ? 'C. Sun, M. Lucic, C. Schmid' : '3 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">3 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In 2021 IEEE/CVF International Conference on Computer Vision (ICCV)</em>,  Oct 2021
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://ieeexplore.ieee.org/abstract/document/9710415" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Arnab_ViViT_A_Video_Vision_Transformer_ICCV_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>We present pure-transformer based models for video classification, drawing upon the recent success of such models in image classification. Our model extracts spatiotemporal tokens from the input video, which are then encoded by a series of transformer layers. In order to handle the long sequences of tokens encountered in video, we propose several, efficient variants of our model which factorise the spatial- and temporal-dimensions of the input. Although transformer-based models are known to only be effective when large training datasets are available, we show how we can effectively regularise the model during training and leverage pretrained image models to be able to train on comparatively small datasets. We conduct thorough ablation studies, and achieve state-of-the-art results on multiple video classification benchmarks including Kinetics 400 and 600, Epic Kitchens, Something-Something v2 and Moments in Time, outperforming prior methods based on deep 3D convolutional networks.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="thuerey:hal-04083995" class="col-sm-8">
    <!-- Title -->
    <div class="title">Physics-based Deep Learning</div>
    <!-- Author -->
    <div class="author">
      

      
      Nils
            Thuerey, Philipp
            Holl, Maximilian
            Mueller, and
        <span class="more-authors" title="click to view 3 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '3 more authors' ? 'Patrick Schnell, Felix Trost, Kiwon Um' : '3 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">3 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      Sep 2021
    </div>
    <div class="periodical">
      PBDL v0.2, available online at: https://www.physicsbaseddeeplearning.org/
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2109.05237" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>This digital book contains a practical and comprehensive introduction of everything related to deep learning in the context of physical simulations. As much as possible, all topics come with hands-on code examples in the form of Jupyter notebooks to quickly get started. Beyond standard supervised learning from data, we’ll look at physical loss constraints, more tightly coupled learning algorithms with differentiable simulations, as well as reinforcement learning and uncertainty modeling. We live in exciting times: these methods have a huge potential to fundamentally change what computer simulations can achieve.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Thompson9563954" class="col-sm-8">
    <!-- Title -->
    <div class="title">Deep Learning’s Diminishing Returns: The Cost of Improvement is Becoming Unsustainable</div>
    <!-- Author -->
    <div class="author">
      

      
      Neil C.
            Thompson, Kristjan
            Greenewald, Keeheon
            Lee, and
        <span class="more-authors" title="click to view 1 more author" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '1 more author' ? 'Gabriel F. Manso' : '1 more author';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">1 more author</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>IEEE Spectrum</em>,  Sep 2021
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://ieeexplore.ieee.org/document/9563954" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Deep learning is now being used to translate between languages, predict how proteins fold, analyze medical scans, and play games as complex as Go, to name just a few applications of a technique that is now becoming pervasive. Success in those and other realms has brought this machine-learning technique from obscurity in the early 2000s to dominance today. • Although deep learning’s rise to fame is relatively recent, its origins are not. In 1958, back when mainframe computers filled rooms and ran on vacuum tubes, knowledge of the interconnections between neurons in the brain inspired Frank Rosenblatt at Cornell to design the first artificial neural network, which he presciently described as a “pattern-recognizing device.” But Rosenblatt’s ambitions outpaced the capabilities of his era—and he knew it. Even his inaugural paper was forced to acknowledge the voracious appetite of neural networks for computational power, bemoaning that “as the number of connections in the network increases…the burden on a conventional digital computer soon becomes excessive.” • Fortunately for such artificial neural networks—later rechristened “deep learning” when they included extra layers of neurons—decades of Moore’s Law and other improvements in computer hardware yielded a roughly 10-million-fold increase in the number of computations that a computer could do in a second. So when researchers returned to deep learning in the late 2000s, they wielded tools equal to the challenge.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="10.1007/978-3-030-93135-3_2" class="col-sm-8">
    <!-- Title -->
    <div class="title">Software Engineering as an Alchemical Process: Establishing a Philosophy of the Discipline</div>
    <!-- Author -->
    <div class="author">
      

      
      Manuel
            Mazzara, Mirko
            Farina, Adéla
            Krylová, and
        <span class="more-authors" title="click to view 2 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '2 more authors' ? 'Elizaveta Semenova, Mosab Mohamed' : '2 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">2 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Frontiers in Software Engineering</em>,  Sep 2021
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Far from being a bizarre pastime, alchemy played a crucially important role in the history of science, being supported and promoted by leading political and scientific figures (such as Rudolf II, Jābir ibn Hayyān, Gerard of Cremona, Adelard of Bath, Roger Bacon, Paracelsus, and even Newton). To understand alchemy, however, one has to approach it from both a material and a spiritual (perhaps philosophical) perspective. On the one hand, alchemists wanted to transform, or better transmute, materials (such as lead into gold). On the other hand, though, alchemists were also aiming at transforming qualities and aspects of themselves. In this paper, we show that Computer Science, and in particular Software Engineering, can be partly understood as alchemical processes. We thus draw analogies and specify points of contact between these two, prima facie, distinct and very distant worlds. In doing so, we also formulate and discuss a number of important questions regarding the nature and metaphysics of computation, that can be of interests to many researchers in computer science.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="klinger2021deep" class="col-sm-8">
    <!-- Title -->
    <div class="title">Deep learning, deep change? Mapping the evolution and geography of a general purpose technology</div>
    <!-- Author -->
    <div class="author">
      

      
      Joel
            Klinger, Juan
            Mateos-Garcia, and Konstantinos
            Stathoulopoulos
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Scientometrics</em>,  Sep 2021
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
      
        
          <a href="https://link.springer.com/article/10.1007/s11192-021-03936-9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2020</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="proceedings2020047009" class="col-sm-8">
    <!-- Title -->
    <div class="title">The Neural Network Zoo</div>
    <!-- Author -->
    <div class="author">
      

      
      Stefan
            Leijnen, and Fjodor van
            Veen
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Proceedings</em>,  Sep 2020
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://www.mdpi.com/2504-3900/47/1/9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://www.researchgate.net/publication/341373030_The_Neural_Network_Zoo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>An overview of neural network architectures is presented. Some of these architectures have been created in recent years, whereas others originate from many decades ago. Apart from providing a practical tool for comparing deep learning models, the Neural Network Zoo also uncovers a taxonomy of network architectures, their chronology, and traces back lineages and inspirations for these neural information processing systems.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Strubell_Ganesh_McCallum_2020" class="col-sm-8">
    <!-- Title -->
    <div class="title">Energy and Policy Considerations for Modern Deep Learning Research</div>
    <!-- Author -->
    <div class="author">
      

      
      Emma
            Strubell, Ananya
            Ganesh, and Andrew
            McCallum
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>,  Apr 2020
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://arxiv.org/abs/1906.02243" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://arxiv.org/pdf/1906.02243" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>The field of artificial intelligence has experienced a dramatic methodological shift towards large neural networks trained on plentiful data. This shift has been fueled by recent advances in hardware and techniques enabling remarkable levels of computation, resulting in impressive advances in AI across many applications. However, the massive computation required to obtain these exciting results is costly both financially, due to the price of specialized hardware and electricity or cloud compute time, and to the environment, as a result of non-renewable energy used to fuel modern tensor processing hardware. In a paper published this year at ACL, we brought this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training and tuning neural network models for NLP (Strubell, Ganesh, and McCallum 2019). In this extended abstract, we briefly summarize our findings in NLP, incorporating updated estimates and broader information from recent related publications, and provide actionable recommendations to reduce costs and improve equity in the machine learning and artificial intelligence community</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="bochkovskiy2020yolov4" class="col-sm-8">
    <!-- Title -->
    <div class="title">Yolov4: Optimal speed and accuracy of object detection</div>
    <!-- Author -->
    <div class="author">
      

      
      Alexey
            Bochkovskiy, Chien-Yao
            Wang, and Hong-Yuan Mark
            Liao
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>arXiv preprint arXiv:2004.10934</em>,  Apr 2020
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2004.10934" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is required. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets. We assume that such universal features include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation. We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and combine some of them to achieve state-of-the-art results: 43.5% AP (65.7% AP50) for the MS COCO dataset at a realtime speed of  65 FPS on Tesla V100.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2019</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">Elsevier</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="GREN2019112" class="col-sm-8">
    <!-- Title -->
    <div class="title">Calculating the costs of animal-vehicle accidents involving ungulate in Sweden</div>
    <!-- Author -->
    <div class="author">
      

      
      Ing-Marie
            Gren, and Annika
            Jägerbrand
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Transportation Research Part D: Transport and Environment</em>,  Apr 2019
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361920918305856" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Animal-vehicle collisions (AVCs) involving ungulate species pose a serious problem in many countries, and the prediction of accidents and costs on a regional and national spatial scale is important for efficient accident mitigation. Based on the assumption that AVCs are determined by traffic volume and ungulate population dynamics, this study developed a relatively simple method for calculating and predicting the costs of current and future traffic accidents involving moose, roe deer and wild boar in Sweden. A logistic population model was assumed for all three ungulate species and econometric methods were applied to obtain population growth models based on panel data on traffic accidents, traffic load, hunting bags, hunting licenses and landscape characteristics for each Swedish county and year from 2003 to 2015. The population growth models were used to predict vehicle accidents and costs. The predicted annual discounted costs of AVCs over a 15-year period based on projected ungulate populations and traffic volume fell by 25% from 406 million USD in 2015, however the allocation of costs between ungulates differed. AVCs involving roe deer accounted for the largest share of the costs (54%), but collisions involving wild boar showed the most rapid increase over the study period because of a relatively high estimated growth rate and recent expansion of wild boar populations to several new counties. However, the predicted costs were sensitive to assumptions regarding population dynamics as well as assumptions about future hunting pressure and traffic volume.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="arikan2019surface" class="col-sm-8">
    <!-- Title -->
    <div class="title">Surface defect classification in real-time using convolutional neural networks</div>
    <!-- Author -->
    <div class="author">
      

      
      Selim
            Arikan, Kiran
            Varanasi, and Didier
            Stricker
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>arXiv preprint arXiv:1904.04671</em>,  Apr 2019
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
      
        
          <a href="https://arxiv.org/abs/1904.04671" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://arxiv.org/pdf/1904.04671" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Hao2019" class="col-sm-8">
    <!-- Title -->
    <div class="title">Training a single AI model can emit as much carbon as five cars in their lifetimes</div>
    <!-- Author -->
    <div class="author">
      

      
      Karen
            Hao
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      Apr 2019
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>The artificial-intelligence industry is often compared to the oil industry: once mined and refined, data, like oil, can be a highly lucrative commodity. Now it seems the metaphor may extend even further. Like its fossil-fuel counterpart, the process of deep learning has an outsize environmental impact.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="RAISSI2019686" class="col-sm-8">
    <!-- Title -->
    <div class="title">Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations</div>
    <!-- Author -->
    <div class="author">
      

      
      M.
            Raissi, P.
            Perdikaris, and G.E.
            Karniadakis
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Journal of Computational Physics</em>,  Apr 2019
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0021999118307125" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://arxiv.org/pdf/1711.10561" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2018</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="abou2018municipal" class="col-sm-8">
    <!-- Title -->
    <div class="title">Municipal infrastructure anomaly and defect detection</div>
    <!-- Author -->
    <div class="author">
      

      
      David
            Abou Chacra, and John
            Zelek
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In 2018 26th European Signal Processing Conference (EUSIPCO)</em>,  Apr 2018
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
      
      
        
          <a href="https://www.eurasip.org/Proceedings/Eusipco/Eusipco2018/papers/1570437793.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    

    
  </div>
</div>
</li></ol>
<h2 class="bibliography">2017</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Krizhevsky10.1145/3065386" class="col-sm-8">
    <!-- Title -->
    <div class="title">ImageNet classification with deep convolutional neural networks</div>
    <!-- Author -->
    <div class="author">
      

      
      Alex
            Krizhevsky, Ilya
            Sutskever, and Geoffrey E.
            Hinton
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Commun. ACM</em>,  May 2017
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://dl.acm.org/doi/10.1145/3065386" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://dl.acm.org/doi/pdf/10.1145/3065386" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="lecun2017my" class="col-sm-8">
    <!-- Title -->
    <div class="title">My take on Ali Rahimi’s ‘Test of Time’ award talk at NIPS</div>
    <!-- Author -->
    <div class="author">
      

      
      Yann
            LeCun
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Facebook, https://www. facebook. com/yann. lecun/posts/101 54938130592143</em>,  May 2017
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
      
      
        
          <a href="https://www2.isye.gatech.edu/%C2%A0tzhao80/Yann_Response.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2016</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Redmon2016CVPR" class="col-sm-8">
    <!-- Title -->
    <div class="title">You Only Look Once: Unified, Real-Time Object Detection</div>
    <!-- Author -->
    <div class="author">
      

      
      Joseph
            Redmon, Santosh
            Divvala, Ross
            Girshick, and
        <span class="more-authors" title="click to view 1 more author" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '1 more author' ? 'Ali Farhadi' : '1 more author';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">1 more author</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,  Jun 2016
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Redmon_You_Only_Look_CVPR_2016_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.</p>
      </div>
    

    

    
  </div>
</div>
</li></ol>
<h2 class="bibliography">2008</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="10.1145/1378600.1378605" class="col-sm-8">
    <!-- Title -->
    <div class="title">The pothole patrol: using a mobile sensor network for road surface monitoring</div>
    <!-- Author -->
    <div class="author">
      

      
      Jakob
            Eriksson, Lewis
            Girod, Bret
            Hull, and
        <span class="more-authors" title="click to view 3 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '3 more authors' ? 'Ryan Newton, Samuel Madden, Hari Balakrishnan' : '3 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">3 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Proceedings of the 6th International Conference on Mobile Systems, Applications, and Services</em>, Breckenridge, CO, USA,  Jun 2008
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://dl.acm.org/doi/abs/10.1145/1378600.1378605" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>This paper investigates an application of mobile sensing: detecting and reporting the surface conditions of roads. We describe a system and associated algorithms to monitor this important civil infrastructure using a collection of sensor-equipped vehicles. This system, which we call the Pothole Patrol (P2), uses the inherent mobility of the participating vehicles, opportunistically gathering data from vibration and GPS sensors, and processing the data to assess road surface conditions. We have deployed P2 on 7 taxis running in the Boston area. Using a simple machine-learning approach, we show that we are able to identify potholes and other severe road surface anomalies from accelerometer data. Via careful selection of training data and signal features, we have been able to build a detector that misidentifies good road segments as having potholes less than 0.2% of the time. We evaluate our system on data from thousands of kilometers of taxi drives, and show that it can successfully detect a number of real potholes in and around the Boston area. After clustering to further reduce spurious detections, manual inspection of reported potholes shows that over 90% contain road anomalies in need of repair.</p>
      </div>
    

    

    
  </div>
</div>
</li></ol>
<h2 class="bibliography">1967</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100" style="background-color:#009f36">
            
              <div>Vision</div>
            
          </abbr>
        
      
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
    <img src="/assets/img/publication_preview/wave-mechanics.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wave-mechanics.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="przibram1967letters" class="col-sm-8">
    <!-- Title -->
    <div class="title">Letters on wave mechanics</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Albert
            Einstein</em>, <a href="https://en.wikipedia.org/wiki/Erwin_Schr%C3%B6dinger" rel="external nofollow noopener" target="_blank">Erwin
              Schrödinger</a>, <a href="https://en.wikipedia.org/wiki/Max_Planck" rel="external nofollow noopener" target="_blank">Max
              Planck</a>, and
        <span class="more-authors" title="click to view 2 more authors" onclick="
              var element = $(this);
              element.attr('title', '');
              var more_authors_text = element.text() == '2 more authors' ? 'Hendrik Antoon Lorentz, Karl Przibram' : '2 more authors';
              var cursorPosition = 0;
              var textAdder = setInterval(function(){
                element.html(more_authors_text.substring(0, cursorPosition + 1));
                if (++cursorPosition == more_authors_text.length){
                  clearInterval(textAdder);
                }
            }, '10');
          ">2 more authors</span>
      
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      Jun 1967
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
      
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    
      <!-- Hidden bibtex block -->
      <div class="bibtex hidden">
        <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@book</span><span class="p">{</span><span class="nl">przibram1967letters</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Letters on wave mechanics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{1967}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Vision}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
      </div>
    

    
  </div>
</div>
</li></ol>
<h2 class="bibliography">1956</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
        
          
          

<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
    <img src="/assets/img/publication_preview/brownian-motion.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="brownian-motion.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="einstein1956investigations" class="col-sm-8">
    <!-- Title -->
    <div class="title">Investigations on the Theory of the Brownian Movement</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Albert
            Einstein</em>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      Jun 1956
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
      
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    
      <!-- Hidden bibtex block -->
      <div class="bibtex hidden">
        <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@book</span><span class="p">{</span><span class="nl">einstein1956investigations</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Investigations on the Theory of the Brownian Movement}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Einstein, Albert}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{1956}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Courier Corporation}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
      </div>
    

    
  </div>
</div>
</li></ol>
<h2 class="bibliography">1950</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100" style="background-color:#00369f">
            
              <a href="https://aapt.scitation.org/journal/ajp" rel="external nofollow noopener" target="_blank">AJP</a>
            
          </abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="einstein1950meaning" class="col-sm-8">
    <!-- Title -->
    <div class="title">The meaning of relativity</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Albert
            Einstein</em>, and AH
            Taub
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>American Journal of Physics</em>,  Jun 1950
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
      
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    
      <!-- Hidden bibtex block -->
      <div class="bibtex hidden">
        <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">einstein1950meaning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The meaning of relativity}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Einstein, Albert and Taub, AH}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{American Journal of Physics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{403--404}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{1950}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{American Association of Physics Teachers}</span>
<span class="p">}</span></code></pre></figure>
      </div>
    

    
  </div>
</div>
</li></ol>
<h2 class="bibliography">1935</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">
            
              <a href="https://journals.aps.org/" rel="external nofollow noopener" target="_blank">PhysRev</a>
            
          </abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="PhysRev.47.777" class="col-sm-8">
    <!-- Title -->
    <div class="title">Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>A.
            Einstein<sup>*†</sup></em>, <a href="https://en.wikipedia.org/wiki/Boris_Podolsky" rel="external nofollow noopener" target="_blank">B.
              Podolsky<sup>*</sup></a>, and <a href="https://en.wikipedia.org/wiki/Nathan_Rosen" rel="external nofollow noopener" target="_blank">N.
              Rosen<sup>*</sup></a>
      
        <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* Example use of superscripts&lt;br&gt;† Albert Einstein">
        </i>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Phys. Rev.</em>, New Jersey. <em>More Information</em> can be <a href="https://github.com/alshedivat/al-folio/" rel="external nofollow noopener" target="_blank">found here</a>
,  May 1935
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
        
          <a href="https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="/assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
        
      
      
      
        <a href="https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a>
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
        <div class="badges">
          
            <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-altmetric-id="248277"></span>
          
          
            <span class="__dimensions_badge_embed__" data-doi="10.1103/PhysRev.47.777" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=dV8LzD8AAAAJ&amp;citation_for_view=dV8LzD8AAAAJ:qyhmnyLat1gC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations">
            </a>
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.</p>
      </div>
    

    

    
  </div>
</div>
</li></ol>
<h2 class="bibliography">1920</h2>
<ol class="bibliography"><li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="einstein1920relativity" class="col-sm-8">
    <!-- Title -->
    <div class="title">Relativity: the Special and General Theory</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Albert
            Einstein</em>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      May 1920
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
      
        
          <a href="/assets/html/relativity.html" class="btn btn-sm z-depth-0" role="button">HTML</a>
        
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    

    
  </div>
</div>
</li></ol>
<h2 class="bibliography">1905</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="einstein1905molekularkinetischen" class="col-sm-8">
    <!-- Title -->
    <div class="title">Über die von der molekularkinetischen Theorie der Wärme geforderte Bewegung von in ruhenden Flüssigkeiten suspendierten Teilchen</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>A.
            Einstein</em>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Annalen der physik</em>,  May 1905
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">Ann. Phys.</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="einstein1905movement" class="col-sm-8">
    <!-- Title -->
    <div class="title">Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>A.
            Einstein</em>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Ann. Phys.</em>,  May 1905
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
      
    </div>
  

  <!-- Entry bib key -->
  <div id="einstein1905electrodynamics" class="col-sm-8">
    <!-- Title -->
    <div class="title">On the electrodynamics of moving bodies</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>A.
            Einstein</em>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em></em> May 1905
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
      
      
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    

    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">Ann. Phys.</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="einstein1905photoelectriceffect" class="col-sm-8">
    <!-- Title -->
    <div class="title">Über einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Albert
            Einstein</em>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Ann. Phys.</em>,  May 1905
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
        <a class="award btn btn-sm z-depth-0" role="button">Nobel Prize</a>
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
      
      
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      
      
    

    
      <!-- Hidden Award block -->
      <div class="award hidden d-print-inline">
        <p></p>
<p>Albert Einstein receveid the <strong>Nobel Prize in Physics</strong> 1921 <em>for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect</em></p>

      </div>
    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>This is the abstract text.</p>
      </div>
    

    
      <!-- Hidden bibtex block -->
      <div class="bibtex hidden">
        <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">einstein1905photoelectriceffect</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Einstein, Albert}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Ann. Phys.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{322}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{132--148}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{1905}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1002/andp.19053220607}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
      </div>
    

    
  </div>
</div>
</li>
</ol>

</div>

  </article>

  

  
</div>

      
    </div>

    <!-- Footer -->
    
  <footer class="fixed-bottom" role="contentinfo">
    <div class="container mt-0">
      © Copyright 2024
      Algotechniq
      
      . 
      
      
    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<!-- <script src="/assets/js/mdb.min.js"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
  <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>


    

    

    

    

    

    

    

    

    

  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>



<!-- Bootstrap Table -->


<!-- Load Common JS -->
<script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script>
<script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script>
<script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script>

<!-- Jupyter Open External Links New Tab -->
<script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script>



    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>


  <script async src="https://badge.dimensions.ai/badge.js"></script>


    
  
    <!-- MathJax -->
    <script type="text/javascript">
      window.MathJax = {
        tex: {
          tags: 'ams',
        },
      };
    </script>
    <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script>
    <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script>
  


    

    



    
  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    /*
     * This JavaScript code has been adapted from the article
     * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar,
     * published on the website https://css-tricks.com on the 7th of May, 2014.
     * Couple of changes were made to the original code to make it compatible
     * with the `al-foio` theme.
     */
    const progressBar = $('#progress');
    /*
     * We set up the bar after all elements are done loading.
     * In some cases, if the images in the page are larger than the intended
     * size they'll have on the page, they'll be resized via CSS to accomodate
     * the desired size. This mistake, however, breaks the computations as the
     * scroll size is computed as soon as the elements finish loading.
     * To account for this, a minimal delay was introduced before computing the
     * values.
     */
    window.onload = function () {
      setTimeout(progressBarSetup, 50);
    };
    /*
     * We set up the bar according to the browser.
     * If the browser supports the progress element we use that.
     * Otherwise, we resize the bar thru CSS styling
     */
    function progressBarSetup() {
      if ('max' in document.createElement('progress')) {
        initializeProgressElement();
        $(document).on('scroll', function () {
          progressBar.attr({ value: getCurrentScrollPosition() });
        });
        $(window).on('resize', initializeProgressElement);
      } else {
        resizeProgressBar();
        $(document).on('scroll', resizeProgressBar);
        $(window).on('resize', resizeProgressBar);
      }
    }
    /*
     * The vertical scroll position is the same as the number of pixels that
     * are hidden from view above the scrollable area. Thus, a value > 0 is
     * how much the user has scrolled from the top
     */
    function getCurrentScrollPosition() {
      return $(window).scrollTop();
    }

    function initializeProgressElement() {
      let navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      progressBar.css({ top: navbarHeight });
      progressBar.attr({
        max: getDistanceToScroll(),
        value: getCurrentScrollPosition(),
      });
    }
    /*
     * The offset between the html document height and the browser viewport
     * height will be greater than zero if vertical scroll is possible.
     * This is the distance the user can scroll
     */
    function getDistanceToScroll() {
      return $(document).height() - $(window).height();
    }

    function resizeProgressBar() {
      progressBar.css({ width: getWidthPercentage() + '%' });
    }
    // The scroll ratio equals the percentage to resize the bar
    function getWidthPercentage() {
      return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
    }
  </script>


    

    

    

    
  <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script>
  <script>
    addBackToTop();
  </script>


    
  <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script>
  <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys>
  <script>
    let searchTheme = determineComputedTheme();
    const ninjaKeys = document.querySelector('ninja-keys');

    if (searchTheme === 'dark') {
      ninjaKeys.classList.add('dark');
    } else {
      ninjaKeys.classList.remove('dark');
    }

    const openSearchModal = () => {
      // collapse navbarNav if expanded on mobile
      const $navbarNav = $('#navbarNav');
      if ($navbarNav.hasClass('show')) {
        $navbarNav.collapse('hide');
      }
      ninjaKeys.open();
    };
  </script>
  <script>
    // get the ninja-keys element
    const ninja = document.querySelector('ninja-keys');

    // add the home and posts menu items
    ninja.data = [{
        id: "nav-home",
        title: "home",
        section: "Navigation",
        handler: () => {
          window.location.href = "/";
        },
      },{id: "nav-projects",
              title: "projects",
              description: "A growing collection of Algotechniq projects",
              section: "Navigation",
              handler: () => {
                window.location.href = "/projects/";
              },
            },{id: "nav-blog",
              title: "blog",
              description: "",
              section: "Navigation",
              handler: () => {
                window.location.href = "/blog/";
              },
            },{id: "nav-about",
              title: "about",
              description: "Summary description of Algotechniq LLC.",
              section: "Navigation",
              handler: () => {
                window.location.href = "/cv/";
              },
            },{id: "post-ai-on-jetson",
          
            title: "AI on Jetson",
          
          description: "In four bipedal steps",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2024/ai-on-jetson/";
            
          },
        },{id: "post-yolo",
          
            title: "YOLO",
          
          description: "Illustrating a fast and accurate object detection algorithm",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2024/yolov8/";
            
          },
        },{id: "post-deeply-learning-physics",
          
            title: "Deeply Learning Physics",
          
          description: "A few notes in a Jupyter notebook",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2024/pbdl-jupyter/";
            
          },
        },{id: "post-the-jetson-evolution",
          
            title: "The Jetson Evolution",
          
          description: "As Nvidia evolves Jetson, embedded systems thrive",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2024/jetson-evolution/";
            
          },
        },{id: "post-bounded-performance-uncovering-the-roofline-model",
          
            title: "Bounded Performance: Uncovering the Roofline Model",
          
          description: "Is your AI algorithm computation-bound or memory-bound?",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/assets/pdf/roof.pdf";
            
          },
        },{id: "post-neural-nonlinearities",
          
            title: "Neural Nonlinearities",
          
          description: "What makes neural nets so powerful?",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/assets/pdf/nonlinear.pdf";
            
          },
        },{id: "post-ai-39-s-carbon-footprint",
          
            title: "AI's Carbon Footprint",
          
          description: "The quintillions are alarming",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2023/ai-carbon-footprint/";
            
          },
        },{id: "post-the-bottom-up-magic-of-deep-learning",
          
            title: "The Bottom-Up Magic of Deep Learning",
          
          description: "From alchemy to architecture",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2023/dnn-bottomup/";
            
          },
        },{id: "post-crafting-neural-networks",
          
            title: "Crafting Neural Networks",
          
          description: "Building layers bottom-up",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2023/nn-zoo/";
            
          },
        },{id: "post-claws-of-concern",
          
            title: "Claws of Concern",
          
          description: "Bears attacking Japan",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/blog/2023/bears-attack/";
            
          },
        },{id: "news-a-simple-inline-announcement",
              title: 'A simple inline announcement.',
              description: "",
              section: "News",},{id: "news-a-long-announcement-with-details",
              title: 'A long announcement with details',
              description: "",
              section: "News",handler: () => {
                  window.location.href = "/news/announcement_2/";
                },},{id: "news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",
              title: 'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',
              description: "",
              section: "News",},{id: "projects-highsafe",
              title: 'HighSafe',
              description: "Instant accident alerts for safer roads",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/1_project/";
                },},{id: "projects-deephole",
              title: 'DeepHole',
              description: "Real-time road quality detection on Edge",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/2_project/";
                },},{id: "projects-concretevision",
              title: 'ConcreteVision',
              description: "Real-time concrete pouring monitor",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/3_project/";
                },},{id: "projects-smartscan",
              title: 'SmartScan',
              description: "Detecting surface defects with deep learning",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/4_project/";
                },},{id: "projects-autoclaim-ai",
              title: 'AutoClaim AI',
              description: "Precision damage detection for smarter insurance",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/5_project/";
                },},{id: "projects-wildsight",
              title: 'WildSight',
              description: "Precision wildlife detection with deep learning",
              section: "Projects",handler: () => {
                  window.location.href = "/projects/6_project/";
                },},{
            id: 'socials-email',
            title: 'Send email',
            section: 'Socials',
            handler: () => {
              window.open("mailto:%6B%61%6D%62%69%7A@%67%6D%61%69%6C.%63%6F%6D", "_blank");
            },
          },{
            id: 'socials-google-scholar',
            title: 'Google Scholar',
            section: 'Socials',
            handler: () => {
              window.open("https://scholar.google.com/citations?user=dV8LzD8AAAAJ", "_blank");
            },
          },];
  </script>
  <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script>


  </body>
</html>
